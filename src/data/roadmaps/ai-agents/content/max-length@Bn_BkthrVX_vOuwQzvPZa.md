# Max Length

Max Length sets the maximum number of tokens a language model can generate in one reply. Tokens are pieces of textâ€”roughly 100 tokens equals a short paragraph. A small limit saves time and cost but risks cutting answers short. A large limit allows full, detailed replies but needs more compute and can lose focus. Choose limits based on the task: short limits for tweets, longer ones for articles. Tuning Max Length carefully helps balance clarity, speed, and cost.

Visit the following resources to learn more:

- [@official@OpenAI Token Usage](https://platform.openai.com/docs/guides/gpt/managing-tokens)  
- [@official@Size and Max Token Limits](https://docs.anthropic.com/claude/docs/size-and-token-limits)  
- [@article@Utilising Max Token Context Window of Anthropic Claude](https://medium.com/@nampreetsingh/utilising-max-token-context-window-of-anthropic-claude-on-amazon-bedrock-7377d94b2dfa)  
- [@article@Controlling the Length of OpenAI Model Responses](https://help.openai.com/en/articles/5072518-controlling-the-length-of-openai-model-responses)  
- [@article@Max Model Length in AI](https://www.restack.io/p/ai-model-answer-max-model-length-cat-ai)
- [@video@Understanding ChatGPT/OpenAI Tokens](https://youtu.be/Mo3NV5n1yZk)