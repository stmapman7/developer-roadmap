# Black Box Testing

In AI Red Teaming, black-box testing involves probing the AI system with inputs and observing outputs without any knowledge of the model's architecture, training data, or internal logic. This simulates an external attacker and is crucial for finding vulnerabilities exploitable through publicly accessible interfaces, such as prompt injection or safety bypasses discoverable via API interaction.

Learn more from the following resources:

- [@article@Black-Box, Gray Box, and White-Box Penetration Testing](https://www.eccouncil.org/cybersecurity-exchange/penetration-testing/black-box-gray-box-and-white-box-penetration-testing-importance-and-uses/)
- [@article@What is Black Box Testing](https://www.imperva.com/learn/application-security/black-box-testing/)
- [@guide@LLM red teaming guide (open source)](https://www.promptfoo.dev/docs/red-team/)
