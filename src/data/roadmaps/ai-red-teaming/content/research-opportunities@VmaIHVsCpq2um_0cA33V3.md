# Research Opportunities

AI Red Teaming relies on ongoing research. Key areas needing further investigation include scalable methods for finding elusive vulnerabilities, understanding emergent behaviors in complex models, developing provable safety guarantees, creating better benchmarks for AI security, and exploring the socio-technical aspects of AI misuse and defense.

Learn more from the following resources:

- [@article@Cutting-Edge Research on AI Security bolstered with new Challenge Fund](https://www.gov.uk/government/news/cutting-edge-research-on-ai-security-bolstered-with-new-challenge-fund-to-ramp-up-public-trust-and-adoption)
- [@research@Careers | The AI Security Institute (AISI)](https://www.aisi.gov.uk/careers)
- [@research@Research - Anthropic](https://www.anthropic.com/research)
