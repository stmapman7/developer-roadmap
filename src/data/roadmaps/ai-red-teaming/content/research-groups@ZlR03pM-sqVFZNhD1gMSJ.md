# Research Groups

Following and potentially contributing to research groups at universities (like CMU, Stanford, Oxford), non-profits (like OpenAI, Anthropic), or government bodies (like UK's AISI) focused on AI safety, security, and alignment provides deep insights into emerging threats and mitigation strategies relevant to AI Red Teaming.

Learn more from the following resources:

- [@group@AI Cybersecurity | Global Cyber Security Capacity Centre (Oxford)](https://gcscc.ox.ac.uk/ai-security)
- [@group@Anthropic Research](https://www.anthropic.com/research)
- [@group@Center for AI Safety](https://www.safe.ai/)
- [@group@The AI Security Institute (AISI)](https://www.aisi.gov.uk/)
